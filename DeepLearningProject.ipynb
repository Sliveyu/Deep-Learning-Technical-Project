{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02473e19",
   "metadata": {},
   "source": [
    "# Classification Solution 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3d1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Resizing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "train_path = 'archive/train'\n",
    "valid_path = 'archive/valid'\n",
    "test_path = 'archive/test'\n",
    "\n",
    "custom_image_size = (224, 224) \n",
    "target_image_size = (224, 224)  \n",
    "batch_size = 128\n",
    "\n",
    "#normalizing images without aug\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(train_path, target_size=custom_image_size, batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = datagen.flow_from_directory(valid_path, target_size=custom_image_size, batch_size=batch_size, class_mode='categorical')\n",
    "test_generator = datagen.flow_from_directory(test_path, target_size=custom_image_size, batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "#Load Vision Transformer model from TensorFlow Hub\n",
    "hub_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
    "vit_layer = hub.KerasLayer(hub_url, trainable=False)\n",
    "\n",
    "inputs = Input(shape=(custom_image_size[0], custom_image_size[1], 3))\n",
    "x = Resizing(target_image_size[0], target_image_size[1])(inputs) #test code\n",
    "x = vit_layer(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "#compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "history = model.fit(train_generator, epochs=20, validation_data=valid_generator, callbacks=[early_stopping], verbose=1)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time} seconds\")\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "valid_generator2 = datagen.flow_from_directory(test_path, target_size=custom_image_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
    "# Generate predictions\n",
    "y_true = valid_generator2.classes\n",
    "y_pred = np.argmax(model.predict(valid_generator2), axis=1)\n",
    "end_time = time.time()\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Total Inference Time: {inference_time} seconds\")\n",
    "\n",
    "#calc F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "#calc accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true, y_pred, target_names=list(valid_generator2.class_indices.keys())))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Vision Transformer accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Vision Transformer Training and Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model.save('model.keras') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537d5f7",
   "metadata": {},
   "source": [
    "## Visualise images for Data Insight. Uncomment to run independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "n",
    "def load_data(directory, image_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for subdir in os.listdir(directory):\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for file in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, file)\n",
    "                image = load_img(file_path, target_size=image_size)\n",
    "                image = img_to_array(image)\n",
    "                data.append(image)\n",
    "                labels.append(subdir)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "train_path = 'archive/train'\n",
    "valid_path = 'archive/valid'\n",
    "test_path = 'archive/test'\n",
    "\n",
    "\n",
    "image_size = (224, 224)  # Example size, change as needed\n",
    "X_train, y_train = load_data(train_path, image_size=image_size)\n",
    "X_valid, y_valid = load_data(valid_path, image_size=image_size)\n",
    "X_test, y_test = load_data(test_path, image_size=image_size)\n",
    "\n",
    "\n",
    " class_image_count = {}\n",
    "\n",
    "for subdir in os.listdir(train_path):\n",
    "    subdir_path = os.path.join(train_path, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        image_count = len(os.listdir(subdir_path))\n",
    "        class_image_count[subdir] = image_count\n",
    "\n",
    "# Print the number of images in each class\n",
    "print(\"Number of images in each class:\")\n",
    "for class_name, count in class_image_count.items():\n",
    "    print(f'{class_name}: {count} images')\n",
    "\n",
    "\n",
    "min_class = min(class_image_count, key=class_image_count.get)\n",
    "max_class = max(class_image_count, key=class_image_count.get)\n",
    "\n",
    "print(f'\\nClass with the lowest number of images: {min_class} ({class_image_count[min_class]} images)')\n",
    "print(f'Class with the highest number of images: {max_class} ({class_image_count[max_class]} images)')\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(class_image_count.keys(), class_image_count.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Class Distribution of Butterfly and Moths Dataset')\n",
    "plt.show()\n",
    "\n",
    "# Input parms\n",
    "classes_to_show = ['AN 88', 'ATALA', 'BROOKES BIRDWING']  # Replace with class name here\n",
    "images_per_class = 8\n",
    "rows = len(classes_to_show)\n",
    "cols = 8\n",
    "\n",
    "# Filter and sort images\n",
    "def filter_and_sort_images(X, y, classes, images_per_class):\n",
    "    filtered_images = []\n",
    "    filtered_labels = []\n",
    "    for class_name in classes:\n",
    "        indices = [i for i, label in enumerate(y) if label == class_name]\n",
    "        selected_indices = np.random.choice(indices, images_per_class, replace=False)\n",
    "        for idx in selected_indices:\n",
    "            filtered_images.append(X[idx])\n",
    "            filtered_labels.append(y[idx])\n",
    "    return np.array(filtered_images), np.array(filtered_labels)\n",
    "\n",
    "# Visualize filtered images\n",
    "def visualize_images(filtered_images, filtered_labels, rows, cols):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(len(filtered_images)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(filtered_images[i].astype(\"uint8\"))\n",
    "        plt.title(filtered_labels[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "filtered_images, filtered_labels = filter_and_sort_images(X_train, y_train, classes_to_show, images_per_class)\n",
    "visualize_images(filtered_images, filtered_labels, rows, cols)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
